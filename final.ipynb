{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXjw7Jgwu0jH"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.layers import Layer, MaxPooling2D, Input, Flatten, Conv2D, Dense\n",
        "\n",
        "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "#for gpu in gpus:\n",
        "#   tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "POS_PATH = os.path.join('data', 'positive')\n",
        "NEG_PATH = os.path.join('data', 'negative')\n",
        "ANC_PATH = os.path.join('data', 'anchor')\n",
        "os.makedirs(POS_PATH)\n",
        "os.makedirs(NEG_PATH)\n",
        "os.makedirs(ANC_PATH)\n",
        "\n",
        "!tar -xf lfw.tgz\n",
        "\n",
        "for directory in os.listdir('lfw'):\n",
        "    for file in os.listdir(os.path.join('lfw', directory)):\n",
        "        EX_PATH = os.path.join('lfw', directory, file)\n",
        "        NEW_PATH = os.path.join(NEG_PATH, file)\n",
        "        os.replace(EX_PATH, NEW_PATH)\n",
        "\n",
        "import uuid\n",
        "#os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Cut downs frame to 250x250px\n",
        "    frame = frame[120:370,200:450,:]\n",
        "\n",
        "    # Collect anchors\n",
        "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
        "        imgname = os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
        "        # Write out anchor image\n",
        "        cv2.imwrite(imgname, frame)\n",
        "\n",
        "    # Collect positives\n",
        "    if cv2.waitKey(1) & 0xFF == ord('p'):\n",
        "        # Create the unique file path\n",
        "        imgname = os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
        "        # Write out positive image\n",
        "        cv2.imwrite(imgname, frame)\n",
        "\n",
        "    # Show image back to screen\n",
        "    cv2.imshow('Image Collection', frame)\n",
        "\n",
        "    # Breaking gracefully\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "#destroying all the windows\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "anchor = tf.data.Dataset.list_files(ANC_PATH+'\\*.jpg').take(300)\n",
        "positive = tf.data.Dataset.list_files(POS_PATH+'\\*.jpg').take(300)\n",
        "negative = tf.data.Dataset.list_files(NEG_PATH+'\\*.jpg').take(300)\n",
        "\n",
        "dir_test = anchor.as_numpy_iterator()\n",
        "\n",
        "print(dir_test.next())\n",
        "\n",
        "def preprocess(file_path):\n",
        "    byte_img = tf.io.read_file(file_path)\n",
        "    img = tf.io.decode_jpeg(byte_img)\n",
        "    img = tf.image.resize(img, (100,100))\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "img = preprocess('/content/drive/MyDrive/final project/data/anchor/fc28fc18-8abd-09ef-7598-459ebde9a3a1.jpg')\n",
        "\n",
        "print(img.numpy().max())\n",
        "print(img.numpy().min())\n",
        "\n",
        "plt.imshow(img)\n",
        "\n",
        "#dataset.map(preprocess)\n",
        "\n",
        "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
        "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
        "data = positives.concatenate(negatives)\n",
        "\n",
        "samples = data.as_numpy_iterator()\n",
        "\n",
        "example = samples.next()\n",
        "example\n",
        "\n",
        "def preprocess_twin(input_img, validation_img, label):\n",
        "    return(preprocess(input_img), preprocess(validation_img), label)\n",
        "\n",
        "res = preprocess_twin(*example)\n",
        "plt.imshow(res[1])\n",
        "plt.show()\n",
        "res[2]\n",
        "\n",
        "data = data.map(preprocess_twin)\n",
        "data = data.cache()\n",
        "data = data.shuffle(buffer_size=1024)\n",
        "\n",
        "train_data = data.take(round(len(data)*.7))\n",
        "train_data = train_data.batch(16)\n",
        "train_data = train_data.prefetch(8)\n",
        "\n",
        "test_data = data.skip(round(len(data)*.7))\n",
        "test_data = test_data.take(round(len(data)*.3))\n",
        "test_data = test_data.batch(16)\n",
        "test_data = test_data.prefetch(8)\n",
        "\n",
        "\n",
        "def make_embedding():\n",
        "    inp = Input(shape=(100,100,3), name='input_image')\n",
        "\n",
        "    # First block\n",
        "    c1 = Conv2D(64, (10,10), activation='relu')(inp)\n",
        "    m1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n",
        "\n",
        "    # Second block\n",
        "    c2 = Conv2D(128, (7,7), activation='relu')(m1)\n",
        "    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
        "\n",
        "    # Third block\n",
        "    c3 = Conv2D(128, (4,4), activation='relu')(m2)\n",
        "    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
        "\n",
        "    # Final embedding block\n",
        "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
        "    f1 = Flatten()(c4)\n",
        "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
        "\n",
        "\n",
        "    return Model(inputs=[inp], outputs=[d1], name='embedding')\n",
        "embedding = make_embedding()\n",
        "embedding.summary()\n",
        "\n",
        "class L1Dist(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "    def call(self, input_embedding, validation_embedding):\n",
        "        return tf.math.abs(input_embedding - validation_embedding)\n",
        "l1 = L1Dist()\n",
        "l1(anchor_embedding, validation_embedding)\n",
        "\n",
        "input_image = Input(name='input_img', shape=(100,100,3))\n",
        "validation_image = Input(name='validation_img', shape=(100,100,3))\n",
        "inp_embedding = embedding(input_image)[0]\n",
        "val_embedding = embedding(validation_image)\n",
        "siamese_layer = L1Dist()\n",
        "distances = siamese_layer(inp_embedding, val_embedding)\n",
        "classifier = Dense(1, activation='sigmoid')(distances)\n",
        "classifier\n",
        "\n",
        "siamese_network = Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')\n",
        "siamese_network.summary()\n",
        "\n",
        "def make_siamese_model():\n",
        "    input_image = Input(name='input_img', shape=(100,100,3))\n",
        "    validation_image = Input(name='validation_img', shape=(100,100,3))\n",
        "    siamese_layer = L1Dist()\n",
        "    siamese_layer._name = 'distance'\n",
        "    distances = siamese_layer(embedding(input_image), embedding(validation_image))\n",
        "\n",
        "    # Classification layer\n",
        "    classifier = Dense(1, activation='sigmoid')(distances)\n",
        "\n",
        "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')\n",
        "siamese_model = make_siamese_model()\n",
        "\n",
        "siamese_model.summary()\n",
        "\n",
        "binary_cross_loss = tf.losses.BinaryCrossentropy()\n",
        "opt = tf.keras.optimizers.Adam(1e-4) # 0.0001\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
        "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)\n",
        "@tf.function\n",
        "def train_step(batch):\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Get anchor and positive/negative image\n",
        "        X = batch[:2]\n",
        "        # Get label\n",
        "        y = batch[2]\n",
        "        # Forward pass\n",
        "        yhat = siamese_model(X, training=True)\n",
        "        # Calculate loss\n",
        "        loss = binary_cross_loss(y, yhat)\n",
        "    print(loss)\n",
        "\n",
        "    # Calculate gradients\n",
        "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
        "    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "def train(data, EPOCHS):\n",
        "    # Loop through epochs\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
        "        progbar = tf.keras.utils.Progbar(len(data))\n",
        "\n",
        "        # Loop through each batch\n",
        "        for idx, batch in enumerate(data):\n",
        "            # Run train step here\n",
        "            train_step(batch)\n",
        "            progbar.update(idx+1)\n",
        "\n",
        "        # Save checkpoints\n",
        "        if epoch % 10 == 0:\n",
        "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "EPOCHS = 50\n",
        "train(train_data, EPOCHS)\n",
        "\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "\n",
        "test_input, test_val, y_true = test_data.as_numpy_iterator().next()\n",
        "\n",
        "y_hat = siamese_model.predict([test_input, test_val])\n",
        "y_hat\n",
        "[1 if prediction > 0.5 else 0 for prediction in y_hat ]\n",
        "y_true\n",
        "m = Recall()\n",
        "m.update_state(y_true, y_hat)\n",
        "m.result().numpy()\n",
        "m = Precision()\n",
        "m.update_state(y_true, y_hat)\n",
        "m.result().numpy()\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(test_input[0])\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(test_val[0])\n",
        "plt.show()\n",
        "\n",
        "siamese_model.save('siamesemodel.h5')# save model\n",
        "L1Dist\n",
        "model = tf.keras.models.load_model('siamesemodel.h5', custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})\n",
        "model.predict([test_input, test_val])\n",
        "model.summary()\n",
        "# verififictaion functiomm\n",
        "\n",
        "def verify(model, detection_threshold, verification_threshold):\n",
        "    results = []\n",
        "    for image in os.listdir(os.path.join('application_data', 'verification_images')):\n",
        "        input_img = preprocess(os.path.join('application_data', 'input_image', 'input_image.jpg'))\n",
        "        validation_img = preprocess(os.path.join('application_data', 'verification_images', image))\n",
        "        result = model.predict(list(np.expand_dims([input_img, validation_img], axis=1)))\n",
        "        results.append(result)\n",
        "    # Detection Threshold: Metric above which a prediciton is considered positive\n",
        "    detection = np.sum(np.array(results) > detection_threshold)\n",
        "\n",
        "    # Verification Threshold: Proportion of positive predictions / total positive samples\n",
        "    verification = detection / len(os.listdir(os.path.join('application_data', 'verification_images')))\n",
        "    verified = verification > verification_threshold\n",
        "\n",
        "    return results, verified\n",
        "\n",
        "    ### open cv real time verification\n",
        "cap = cv2.VideoCapture(0)\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    frame = frame[120:120+250,200:200+250, :]\n",
        "\n",
        "    cv2.imshow('Verification', frame)\n",
        "\n",
        "    # Verification trigger\n",
        "    if cv2.waitKey(10) & 0xFF == ord('v'):\n",
        "        # Save input image to application_data/input_image folder\n",
        "#         hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "#         h, s, v = cv2.split(hsv)\n",
        "\n",
        "#lim = 255 - 10\n",
        "#v[v > lim] = 255\n",
        "#v[v <= lim] -= 10,  final_hsv = cv2.merge((h, s, v))  img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
        "         cv2.imwrite(os.path.join('application_data', 'input_image', 'input_image.jpg'), frame)\n",
        "        # Run verification\n",
        "        results, verified = verify(model, 0.5, 0.5)\n",
        "        print(verified)\n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "      break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "ZeDgrVj4u5EQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}