{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Create a 2D Numpy array of size 1x3 with elements of your choice\n",
        "arr1=np.array([[1,2,3]])#Your code here\n",
        "#arr1=np.random.randn(1,3)\n",
        "# Create a Numpy array of length 50 with zeroes as its elements\n",
        "arr2=np.zeros(50)#Your code here\n",
        "\n",
        "#Create a Numpy array of length 3x2 with elements of your choice\n",
        "arr3=np.array([[1,2],[3,4],[5,6]])#Your code here\n",
        "\n",
        "arr4=np.dot(arr1,arr3)#Multiply arr1 and arr3 using Numpy functions\n",
        "\n",
        "#Change 5th element of arr2 to a different number\n",
        "#Your code here\n",
        "arr2[4]=10\n",
        "\n",
        "if np.shape(arr4)==(1,2) and arr2[4]!=0:\n",
        "  print(\"Passed\")\n",
        "else:\n",
        "  print(\"Fail\")"
      ],
      "metadata": {
        "id": "Rxfizq1G4D0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "arr1=np.identity(3)\n",
        "arr2=(np.identity(3)*9)+1\n",
        "\n",
        "print(np.dot(arr1,arr2))\n",
        "#Task: Perform the dot product of I and 9I+1 using numpy, here I is referred to as an 3x3 Identity matrix."
      ],
      "metadata": {
        "id": "zVvHEmAA4IpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "## Create a DataFrame from a dictionary\n",
        "data = {\n",
        "    'Name': ['Ramesh', 'Mahesh', 'Suresh'],\n",
        "    'Age': [25, 30, 35],\n",
        "    'City': ['Bangalore', 'Mumbai', 'Delhi']\n",
        "}\n",
        "#Your code here\n",
        "df=pd.DataFrame(data)\n",
        "#Display the first 2 rows of the data frame\n",
        "#Your code here\n",
        "print(df)\n",
        "#Print the age column\n",
        "#Your code here\n",
        "print(df['Name'])\n",
        "print(df['Age'])\n",
        "#Filter rows where age is greater than 26\n",
        "#Your code here\n",
        "df=df[df['Age']>26]\n",
        "#Add a new column 'Country' with the value 'India' for all rows\n",
        "#Your code here\n",
        "#df=df.assign(Country=['India','India'])\n",
        "df['Country']='India'\n",
        "print(df)\n",
        "data1 = {\n",
        "    'Name': ['Ramesh', 'Mahesh', 'Suresh'],\n",
        "    'Age': [25, None, 35],\n",
        "    'City': ['Bangalore', 'Mumbai', 'Delhi']\n",
        "}\n",
        "df2= pd.DataFrame(data1)\n",
        "# Fill missing values in the 'Age' column with the mean age\n",
        "#Your code here\n",
        "df2['Age']=df2['Age'].fillna(df2['Age'].mean())\n",
        "print(df2)"
      ],
      "metadata": {
        "id": "5Q0-K7CC4ZPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np #numpy module. Fill your code\n",
        "xpoints=np.array([1,2,3,4])\n",
        "ypoints=np.array([2,4,6,8])\n",
        "\n",
        "#Plot these points without drawing a line\n",
        "#Your code here\n",
        "#plt.scatter(xpoints,ypoints)\n",
        "\n",
        "\n",
        "#Plotting with marker: Plot these points with a marker(Star marker)\n",
        "#Your code here\n",
        "#plt.scatter(xpoints,ypoints,marker='*')\n",
        "\n",
        "#Using fmt format, add circular marker,red color and Dashed line\n",
        "#Your code here\n",
        "plt.plot(xpoints,ypoints,linestyle='dashed',color='red')\n",
        "#Add xlabel,ylabel and title for the plot.\n",
        "#Your code here\n",
        "plt.xlabel(\"xpoints\")\n",
        "plt.ylabel(\"ypoints\")\n",
        "plt.title(\"plot\")\n",
        "\n",
        "#Create a scatter plot for xpoints and ypoints\n",
        "#Your code here\n",
        "\n",
        "#Set color to the scatter plot. Blue,Green,Red and yellow color for each point respectively\n",
        "colormap=np.array(['b','g','r','y'])\n",
        "plt.scatter(xpoints,ypoints,c=colormap)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QJsp7qXB4d32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "#Set the seed of random to 20\n",
        "#Your code here\n",
        "random.seed(20)\n",
        "arr1=np.array([1,24,31,45,73,81,94,25])\n",
        "sum=0\n",
        "for i in range(4):\n",
        "  arr=random.randint(1,8)\n",
        "  sum += arr1[arr]\n",
        "print(sum)\n",
        "#Using the random module pick 4 different random numbers from arr1 and return their sum.\n",
        "#Your code here"
      ],
      "metadata": {
        "id": "gtLFbsDR4hfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#logistic regression\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "data=np.loadtxt(\"/content/data.txt\",delimiter=',')\n",
        "X=data[:,:2]\n",
        "y=data[:,2]\n",
        "X_train=X\n",
        "y_train=y\n",
        "\n",
        "#plot data to visualise\n",
        "def plot_data(X,y,positive_label=\"y=1\", negative_label=\"y=0\"):\n",
        "#positive_label and negative_label refers to classes of y as y can be 0 or 1\n",
        "    positive = y == 1\n",
        "    negative = y == 0\n",
        "    plt.plot(X[positive, 0], X[positive, 1], 'k+', label=positive_label)\n",
        "    plt.plot(X[negative, 0], X[negative, 1], 'yo', label=negative_label)\n",
        "    plt.xlabel('Test 2')\n",
        "    plt.ylabel('Test 1')\n",
        "    plt.legend(loc=\"upper right\")\n",
        "\n",
        "#While plotting graph the label parameter will be either positive_label or negative_label so plot both the labels for\n",
        "#test\n",
        "\n",
        "plot_data(X_train, y_train[:], positive_label=\"Accepted\", negative_label=\"Rejected\")\n",
        "plt.show()\n",
        "#feature mapping\n",
        "def map_feature(X1,X2):\n",
        "  X1=np.atleast_1d(X1)#convert any input to atleast 1d array\n",
        "  X2=np.atleast_1d(X2)\n",
        "  degree=6#controls highest polynomial degree used to capture non linear relationships\n",
        "  out=[]\n",
        "  for i in range(1,degree+1):\n",
        "    for j in range(i+1):\n",
        "      out.append((X1**(i-j) * (X2**j)))\n",
        "  return np.stack(out, axis=1)#axis 1 is vertical it combines two or more arrays vertically\n",
        "\n",
        "print(\"Original shape of data:\", X_train.shape)\n",
        "\n",
        "mapped_X =  map_feature(X_train[:, 0], X_train[:, 1])\n",
        "print(\"Shape after feature mapping:\", mapped_X.shape)\n",
        "\n",
        "def sigmoid_test(target):\n",
        "    assert np.isclose(target(3.0), 0.9525741268224334), \"Failed for scalar input\"\n",
        "    assert np.allclose(target(np.array([2.5, 0])), [0.92414182, 0.5]), \"Failed for 1D array\"\n",
        "    assert np.allclose(target(np.array([[2.5, -2.5], [0, 1]])),\n",
        "                       [[0.92414182, 0.07585818], [0.5, 0.73105858]]), \"Failed for 2D array\"\n",
        "    print('\\033[92mTests passed!')\n",
        "\n",
        "def compute_cost_test(target):\n",
        "    X = np.array([[0, 0, 0, 0]]).T\n",
        "    y = np.array([0, 0, 0, 0])\n",
        "    w = np.array([0])\n",
        "    b = 1\n",
        "    result = target(X, y, w, b)\n",
        "    if math.isinf(result):\n",
        "        raise ValueError(\"Did you get the sigmoid of z_wb?\")\n",
        "\n",
        "    np.random.seed(17)\n",
        "    X = np.random.randn(5, 2)\n",
        "    y = np.array([1, 0, 0, 1, 1])\n",
        "    w = np.random.randn(2)\n",
        "    b = 0\n",
        "    result = target(X, y, w, b)\n",
        "    assert np.isclose(result, 2.15510667), f\"Wrong output. Expected: {2.15510667} got: {result}\"\n",
        "\n",
        "    X = np.random.randn(4, 3)\n",
        "    y = np.array([1, 1, 0, 0])\n",
        "    w = np.random.randn(3)\n",
        "    b = 0\n",
        "\n",
        "    result = target(X, y, w, b)\n",
        "    assert np.isclose(result, 0.80709376), f\"Wrong output. Expected: {0.80709376} got: {result}\"\n",
        "\n",
        "    X = np.random.randn(4, 3)\n",
        "    y = np.array([1, 0,1, 0])\n",
        "    w = np.random.randn(3)\n",
        "    b = 3\n",
        "    result = target(X, y, w, b)\n",
        "    assert np.isclose(result, 0.4529660647), f\"Wrong output. Expected: {0.4529660647} got: {result}. Did you inizialized z_wb = b?\"\n",
        "\n",
        "    print('\\033[92mTests passed!')\n",
        "\n",
        "\n",
        "\n",
        "def sigmoid(z):\n",
        "  return 1/(1+np.exp(-z))\n",
        "\n",
        "sigmoid_test(sigmoid)#computing cost\n",
        "\n",
        "def compute_cost(X,y,w,b,lambda_=1):\n",
        "#write your code\n",
        "  m=X.shape[0]\n",
        "  model=np.dot(X, w) + b\n",
        "  Y_pred = sigmoid(model)\n",
        "  total_cost =(-1/m)*np.sum(y*np.log(Y_pred)+(1-y)*np.log(1-Y_pred))\n",
        "  return total_cost\n",
        "\n",
        "def compute_cost_reg(X,y,w,b,lambda_=1):\n",
        "  m=X.shape[0]\n",
        "  reg=(lambda_/(2*m))*np.sum(w**2)\n",
        "  model=np.dot(X, w) + b\n",
        "  Y_pred = sigmoid(model)\n",
        "  total_cost =(-1/m)*np.sum(y*np.log(Y_pred)+(1-y)*np.log(1-Y_pred)) +reg\n",
        "  return total_cost\n",
        "\n",
        "test_w = np.array([0.2, 0.2])\n",
        "test_b = -24.\n",
        "cost = compute_cost(X_train, y_train, test_w, test_b)\n",
        "print('Cost at test w,b: {:.3f}'.format(cost))\n",
        "compute_cost_test(compute_cost)\n",
        "\n",
        "def compute_cost_reg_test(target):\n",
        "    np.random.seed(1)\n",
        "    w = np.random.randn(3)\n",
        "    b = 0.4\n",
        "    X = np.random.randn(6, 3)\n",
        "    y = np.array([0, 1, 1, 0, 1, 1])\n",
        "    lambda_ = 0.1\n",
        "    expected_output = target(X, y, w, b, lambda_)\n",
        "\n",
        "    assert np.isclose(expected_output, 0.5469746792761936), f\"Wrong output. Expected: {0.5469746792761936} got:{expected_output}\"\n",
        "\n",
        "    w = np.random.randn(5)\n",
        "    b = -0.6\n",
        "    X = np.random.randn(8, 5)\n",
        "    y = np.array([1, 0, 1, 0, 0, 1, 0, 1])\n",
        "    lambda_ = 0.01\n",
        "    output = target(X, y, w, b, lambda_)\n",
        "    assert np.isclose(output, 1.2608591964119995), f\"Wrong output. Expected: {1.2608591964119995} got:{output}\"\n",
        "\n",
        "    w = np.array([2, 2, 2, 2, 2])\n",
        "    b = 0\n",
        "    X = np.zeros((8, 5))\n",
        "    y = np.array([0.5] * 8)\n",
        "    lambda_ = 3\n",
        "    output = target(X, y, w, b, lambda_)\n",
        "    expected = -np.log(0.5) + 3. / (2. * 8.) * 20.\n",
        "    assert np.isclose(output, expected), f\"Wrong output. Expected: {expected} got:{output}\"\n",
        "\n",
        "    print('\\033[92mAll tests passed!')\n",
        "\n",
        "X_mapped = map_feature(X_train[:, 0], X_train[:, 1])\n",
        "np.random.seed(1)\n",
        "initial_w = np.random.rand(X_mapped.shape[1]) - 0.5\n",
        "initial_b = 0.5\n",
        "lambda_ = 0.5\n",
        "cost = compute_cost_reg(X_mapped, y_train, initial_w, initial_b, lambda_)\n",
        "\n",
        "print(\"Regularised cost :\", cost)\n",
        "\n",
        "#test\n",
        "compute_cost_reg_test(compute_cost_reg)\n",
        "\n",
        "def compute_gradient(X, y, w, b, lambda_=None):\n",
        "  lr=0.003\n",
        "  iters=10000;\n",
        "  n_samples, n_features = X.shape\n",
        "  for i in range(iters):\n",
        "   model=np.dot(X,w)+b\n",
        "   y_pred=sigmoid(model)\n",
        "   dj_dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))\n",
        "   dj_db = (1 / n_samples) * np.sum(y_pred - y)\n",
        "   w -= lr*dj_dw\n",
        "   b -= lr*dj_db\n",
        "   return dj_db,dj_dw\n",
        "\n",
        "def compute_gradient_test(target):\n",
        "    np.random.seed(1)\n",
        "    X = np.random.randn(7, 3)\n",
        "    y = np.array([1, 0, 1, 0, 1, 1, 0])\n",
        "    test_w = np.array([1, 0.5, -0.35])\n",
        "    test_b = 1.7\n",
        "    dj_db, dj_dw  = target(X, y, test_w, test_b)\n",
        "\n",
        "    assert np.isclose(dj_db, 0.28936094), f\"Wrong value for dj_db. Expected: {0.28936094} got: {dj_db}\"\n",
        "    assert dj_dw.shape == test_w.shape, f\"Wrong shape for dj_dw. Expected: {test_w.shape} got: {dj_dw.shape}\"\n",
        "    assert np.allclose(dj_dw, [-0.11999166, 0.41498775, -0.71968405]), f\"Wrong values for dj_dw. Got: {dj_dw}\"\n",
        "\n",
        "    print('\\033[92mTests passed!')\n",
        "\n",
        "test_w = np.array([ 0.2, -0.5])\n",
        "test_b = -24\n",
        "dj_db, dj_dw  = compute_gradient(X_train, y_train, test_w, test_b)\n",
        "\n",
        "print('dj_db at test_w:', dj_db)\n",
        "print('dj_dw at test_w:', dj_dw.tolist())\n",
        "\n",
        "# test\n",
        "compute_gradient_test(compute_gradient)\n",
        "\n",
        "def compute_gradient_reg(X, y, w, b, lambda_=1):\n",
        "  lr=0.003\n",
        "  iters=10000;\n",
        "  n_samples, n_features = X.shape\n",
        "  for i in range(iters):\n",
        "   model=np.dot(X,w)+b\n",
        "   y_pred=sigmoid(model)\n",
        "   dj_dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))+(lambda_ / n_samples) * w\n",
        "   dj_db = (1 / n_samples) * np.sum(y_pred - y)\n",
        "   w -= lr*dj_dw\n",
        "   b -= lr*dj_db\n",
        "   return dj_db,dj_dw\n",
        "\n",
        "def compute_gradient_reg_test(target):\n",
        "    np.random.seed(1)\n",
        "    w = np.random.randn(5)\n",
        "    b = 0.2\n",
        "    X = np.random.randn(7, 5)\n",
        "    y = np.array([0, 1, 1, 0, 1, 1, 0])\n",
        "    lambda_ = 0.1\n",
        "    expected1 = (-0.1506447567869257, np.array([ 0.19530838, -0.00632206,  0.19687367,  0.15741161,  0.02791437]))\n",
        "    dj_db, dj_dw = target(X, y, w, b, lambda_)\n",
        "\n",
        "    assert np.isclose(dj_db, expected1[0]), f\"Wrong dj_db. Expected: {expected1[0]} got: {dj_db}\"\n",
        "    assert np.allclose(dj_dw, expected1[1]), f\"Wrong dj_dw. Expected: {expected1[1]} got: {dj_dw}\"\n",
        "\n",
        "\n",
        "    w = np.random.randn(7)\n",
        "    b = 0\n",
        "    X = np.random.randn(7, 7)\n",
        "    y = np.array([1, 0, 0, 0, 1, 1, 0])\n",
        "    lambda_ = 0\n",
        "    expected2 = (0.02660329857573818, np.array([ 0.23567643, -0.06921029, -0.19705212, -0.0002884 ,  0.06490588,\n",
        "        0.26948175,  0.10777992]))\n",
        "    dj_db, dj_dw = target(X, y, w, b, lambda_)\n",
        "    assert np.isclose(dj_db, expected2[0]), f\"Wrong dj_db. Expected: {expected2[0]} got: {dj_db}\"\n",
        "    assert np.allclose(dj_dw, expected2[1]), f\"Wrong dj_dw. Expected: {expected2[1]} got: {dj_dw}\"\n",
        "\n",
        "    print('\\033[92mTests passed!')\n",
        "\n",
        "X_mapped = map_feature(X_train[:, 0], X_train[:, 1])\n",
        "np.random.seed(1)\n",
        "initial_w  = np.random.rand(X_mapped.shape[1]) - 0.5\n",
        "initial_b = 0.5\n",
        "\n",
        "lambda_ = 0.5\n",
        "dj_db, dj_dw = compute_gradient_reg(X_mapped, y_train, initial_w, initial_b, lambda_)\n",
        "\n",
        "print(f\"dj_db: {dj_db}\" )\n",
        "#test\n",
        "compute_gradient_reg_test(compute_gradient_reg)\n",
        "\n",
        "np.random.seed(1)\n",
        "initial_w = np.random.rand(X_mapped.shape[1])-0.5\n",
        "initial_b = 1.\n",
        "lambda_ = 0.01\n",
        "iterations = 10000\n",
        "alpha = 0.01\n",
        "def gradient_descent(X_mapped, y_train, initial_w, initial_b,\n",
        "                                    compute_cost_reg, compute_gradient_reg,\n",
        "                                    alpha, iterations, lambda_):\n",
        "    w = initial_w\n",
        "    b = initial_b\n",
        "    J_history = []\n",
        "    for i in range(iterations):\n",
        "        dj_db, dj_dw = compute_gradient_reg(X_mapped, y_train, w, b, lambda_)\n",
        "        cost = compute_cost_reg(X_mapped, y_train, w, b, lambda_)\n",
        "        w -= alpha * dj_dw\n",
        "        b -= alpha * dj_db\n",
        "        J_history.append(cost)\n",
        "\n",
        "    return w, b, J_history\n",
        "\n",
        "w,b, J_history= gradient_descent(X_mapped, y_train, initial_w, initial_b,\n",
        "                                    compute_cost_reg, compute_gradient_reg,alpha, iterations, lambda_)\n",
        "\n",
        "def plot_decision_boundary(w,b,X,y):\n",
        "    plot_data(X[:, 0:2], y)\n",
        "    if X.shape[1] <= 2:\n",
        "        plot_x = np.array([min(X[:, 0]), max(X[:, 0])])\n",
        "        plot_y = (-1. / w[1]) * (w[0] * plot_x + b)\n",
        "        plt.plot(plot_x, plot_y, c=\"b\")\n",
        "    else:\n",
        "        u = np.linspace(-1, 1.5, 50)\n",
        "        v = np.linspace(-1, 1.5, 50)\n",
        "        z = np.zeros((len(u), len(v)))\n",
        "        for i in range(len(u)):\n",
        "            for j in range(len(v)):\n",
        "                z[i,j] = sigmoid(np.dot(map_feature(u[i], v[j]), w) + b)\n",
        "        z = z.T\n",
        "        plt.contour(u,v,z, levels = [0.5], colors=\"g\")\n",
        "\n",
        "plot_decision_boundary(w, b, X_mapped, y_train)\n",
        "\n",
        "def predict(X, w, b):\n",
        "  m,n=X.shape\n",
        "  p=np.zeros(m)\n",
        "  #write your code\n",
        "  linear_model = np.dot(X,w) +b\n",
        "  y_predicted = sigmoid(linear_model)\n",
        "  p = [1 if i > 0.5 else 0 for i in y_predicted]\n",
        "  return p\n",
        "\n",
        "p = predict(X_mapped, w, b)\n",
        "print('Accuracy of training model: %f'%(np.mean(p == y_train) * 100))"
      ],
      "metadata": {
        "id": "JLWHOCpZ44np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C_xqCMqr44q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3pbyrbeEMsc",
        "outputId": "3ea68643-e7cc-4567-fb69-b7caa3f9880d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization required, your accuracy is 3.0%\n"
          ]
        }
      ],
      "source": [
        "#linear regression\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "data = pd.read_csv('/content/Training data.csv')\n",
        "x_train = data.iloc[:,0:8]\n",
        "y_train = np.array(data.iloc[:,8]).reshape(-1,1)# reshape function will result in 2d array with shape (n,1)\n",
        "#plt.scatter(x_train[1:,7],y_train[1:],s=2)\n",
        "#for n in x_train:\n",
        "    #plt.plot(y_train,x_train[n])\n",
        "def feature_changing(x_train):\n",
        "  x_train = pd.get_dummies(x_train, columns = ['internet', 'sex'],drop_first=True)\n",
        "  return x_train\n",
        "\n",
        "def z_score(x_train):\n",
        "  x_mean=x_train.mean()\n",
        "  x_std=x_train.std()\n",
        "  x_train=(x_train-x_mean)/x_std\n",
        "  return x_train,x_std,x_mean\n",
        "\n",
        "def cost(x_train,y_train,w,b):\n",
        "  y_pred=np.dot(x_train,w)+b\n",
        "  loss = np.mean((y_train-y_pred)**2)\n",
        "  return loss\n",
        "\n",
        "def gradient_descent(x_train,y_train,w,b):\n",
        "  lr=0.01\n",
        "  iters=10000;\n",
        "  for i in range(iters):\n",
        "   n_samples=len(y_train)\n",
        "   y_pred=np.dot(x_train,w)+b\n",
        "   dw = (1 / n_samples) * np.dot(x_train.T, (y_pred - y_train))\n",
        "   db = (1 / n_samples) * np.sum(y_pred - y_train)\n",
        "   w -= lr*dw\n",
        "   b -= lr*db\n",
        "  return w,b\n",
        "\n",
        "x_train = feature_changing(x_train)\n",
        "x_train = x_train.astype(np.float64)\n",
        "x_train,x_std,x_mean = z_score(x_train)\n",
        "\n",
        "np.random.seed(2147483647)\n",
        "w = np.random.randn(x_train.shape[1],1)\n",
        "b = np.random.randn(1)\n",
        "\n",
        "old_cost = 0\n",
        "new_cost = cost(x_train, y_train, w, b)\n",
        "tolerance = 0.00001\n",
        "\n",
        "while abs(old_cost - new_cost) > tolerance:\n",
        "    old_cost = new_cost\n",
        "    w, b = gradient_descent(x_train, y_train, w, b)\n",
        "    new_cost = cost(x_train, y_train, w, b)\n",
        "\n",
        "\n",
        "x_predict = pd.read_csv('/content/Training data.csv').iloc[:,:8]\n",
        "x_predict = feature_changing(x_predict)\n",
        "x_predict = (x_predict - x_mean)/x_std\n",
        "ans = pd.read_csv('/content/Test data.csv').iloc[:,8].to_numpy()\n",
        "\n",
        "y_predict = np.dot(x_predict,w) + b\n",
        "\n",
        "accuracy = 0\n",
        "for dim in range(len(ans)):\n",
        "  if abs(y_predict[dim]-ans[dim])<0.5: # do not change the tolerance as you'll be checked on +- 0.5 error only\n",
        "    accuracy += 1\n",
        "accuracy = round(accuracy*100/200.0,2)\n",
        "ok = 'Congratulations' if accuracy>95 else 'Optimization required'\n",
        "print(f\"{ok}, your accuracy is {accuracy}%\")"
      ]
    }
  ]
}